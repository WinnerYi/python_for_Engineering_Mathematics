#!/usr/bin/env python3
"""
FaceSwap + éŸ³è¨Šåˆä½µå·¥å…·
åŠŸèƒ½ï¼š
1ï¸âƒ£ ä½¿ç”¨ InsightFace / GFPGAN åšå½±ç‰‡æ›è‡‰
2ï¸âƒ£ å°‡æŒ‡å®šéŸ³è¨Šæˆ–åŸå½±ç‰‡éŸ³è¨Šåˆä½µåˆ°æ›è‡‰å½±ç‰‡
"""

import os
import sys
import cv2
import argparse
import subprocess
from pathlib import Path

# --- FaceSwap ç›¸é—œå¥—ä»¶ ---
try:
    from insightface.app import FaceAnalysis
    from insightface.model_zoo import get_model
except ImportError:
    print("âŒ æœªå®‰è£ InsightFaceï¼Œè«‹å…ˆåŸ·è¡Œ: pip install insightface")
    sys.exit(1)

try:
    from gfpgan import GFPGANer
    GFPGAN_AVAILABLE = True
except ImportError:
    GFPGAN_AVAILABLE = False

# -------------------- FaceSwapper é¡åˆ¥ --------------------
class FaceSwapper:
    def __init__(self, model_path='inswapper_128.onnx', use_gpu=False, enhance=False):
        """
        åˆå§‹åŒ– FaceSwapper
        model_path: InsightFace æ›è‡‰æ¨¡å‹è·¯å¾‘
        use_gpu: æ˜¯å¦ä½¿ç”¨ GPU
        enhance: æ˜¯å¦ä½¿ç”¨ GFPGAN å¢å¼·è‡‰éƒ¨ç´°ç¯€
        """
        print("ğŸ”§ è¼‰å…¥ InsightFace æ¨¡å‹...")
        self.face_detector = FaceAnalysis(name='buffalo_l')
        ctx_id = 0 if use_gpu else -1
        self.face_detector.prepare(ctx_id=ctx_id, det_size=(640, 640))

        providers = ['CUDAExecutionProvider'] if use_gpu else ['CPUExecutionProvider']
        self.swapper = get_model(model_path, providers=providers)
        print("âœ… InsightFace æ¨¡å‹è¼‰å…¥å®Œæˆ")

        # GFPGAN å¢å¼·è¨­å®š
        self.restorer = None
        if enhance:
            if not GFPGAN_AVAILABLE:
                print("âŒ æœªå®‰è£ GFPGAN å¥—ä»¶ï¼Œç„¡æ³•å•Ÿç”¨å¢å¼·")
                sys.exit(1)
            print("ğŸ”§ è¼‰å…¥ GFPGAN æ¨¡å‹...")
            self.restorer = GFPGANer(
                model_path='https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth',
                upscale=1, arch='clean', channel_multiplier=2, bg_upsampler=None
            )
            print("âœ… GFPGAN æ¨¡å‹è¼‰å…¥å®Œæˆ")

    def get_faces(self, image):
        """å–å¾—å½±åƒä¸­çš„æ‰€æœ‰äººè‡‰"""
        return self.face_detector.get(image)

    def swap_video(self, source_path, video_path, temp_output, face_index=0):
        """
        å°‡å½±ç‰‡ä¸­çš„äººè‡‰æ›æˆä¾†æºäººè‡‰
        source_path: ä¾†æºäººè‡‰åœ–ç‰‡
        video_path: ç›®æ¨™å½±ç‰‡
        temp_output: æš«å­˜è¼¸å‡ºå½±ç‰‡è·¯å¾‘
        face_index: è‹¥ä¾†æºåœ–æœ‰å¤šå¼µè‡‰ï¼Œé¸æ“‡å“ªä¸€å¼µ
        """
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ ç„¡æ³•é–‹å•Ÿå½±ç‰‡ {video_path}")
            return False

        # å½±ç‰‡è³‡è¨Š
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # å»ºç«‹ VideoWriter ç‰©ä»¶
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(temp_output, fourcc, fps, (width, height))

        # è®€å–ä¾†æºäººè‡‰
        source_img = cv2.imread(source_path)
        source_faces = self.get_faces(source_img)
        if not source_faces:
            print("âŒ æœªåµæ¸¬åˆ°ä¾†æºäººè‡‰")
            cap.release()
            out.release()
            return False
        source_face = source_faces[face_index]

        print(f"ğŸ¬ é–‹å§‹è™•ç† {total_frames} å¹€å½±ç‰‡...")
        processed = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # åµæ¸¬ç›®æ¨™å½±ç‰‡ä¸­çš„äººè‡‰ä¸¦æ›è‡‰
            target_faces = self.get_faces(frame)
            if target_faces:
                swapped = self.swapper.get(frame, target_faces[0], source_face, paste_back=True)
                if swapped is not None:
                    frame = swapped
                    # è‹¥å•Ÿç”¨ GFPGAN å¢å¼·
                    if self.restorer is not None:
                        _, _, restored = self.restorer.enhance(
                            frame, has_aligned=False, only_center_face=False, paste_back=True
                        )
                        if restored is not None:
                            frame = restored
            out.write(frame)
            processed += 1

        cap.release()
        out.release()
        print(f"âœ… æš«å­˜æ›è‡‰å½±ç‰‡å·²ä¿å­˜: {temp_output}")
        return True

# -------------------- éŸ³è¨Šåˆä½µå‡½å¼ --------------------
def merge_audio(video_path, audio_path, output_path):
    """
    ä½¿ç”¨ ffmpeg å°‡å½±ç‰‡èˆ‡éŸ³è¨Šåˆä½µ
    video_path: å½±ç‰‡æª”
    audio_path: éŸ³è¨Šæª”
    output_path: åˆä½µå¾Œè¼¸å‡ºæª”
    """
    if not os.path.isfile(video_path):
        print(f"âŒ æ‰¾ä¸åˆ°å½±ç‰‡æª”: {video_path}")
        return False
    if not os.path.isfile(audio_path):
        print(f"âŒ æ‰¾ä¸åˆ°éŸ³è¨Šæª”: {audio_path}")
        return False

    cmd = [
        "ffmpeg", "-y",
        "-i", video_path,
        "-i", audio_path,
        "-c:v", "copy",        # å½±ç‰‡ç›´æ¥è¤‡è£½ï¼Œä¸é‡æ–°ç·¨ç¢¼
        "-c:a", "aac",         # éŸ³è¨Šè½‰ AAC
        "-b:a", "192k",        # éŸ³è¨Šä½å…ƒç‡
        "-map", "0:v:0",       # å½±ç‰‡ä¾†æºå–ç¬¬ä¸€å€‹è¼¸å…¥
        "-map", "1:a:0",       # éŸ³è¨Šä¾†æºå–ç¬¬äºŒå€‹è¼¸å…¥
        "-shortest",           # ä»¥æœ€çŸ­é•·åº¦ç‚ºæº–
        output_path
    ]
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if result.returncode != 0:
        print("âŒ ffmpeg åˆä½µéŒ¯èª¤:\n", result.stderr)
        return False
    print(f"âœ… æœ€çµ‚å½±ç‰‡å·²ä¿å­˜: {output_path}")
    return True

# -------------------- ä¸»ç¨‹å¼ --------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--source", required=True, help="ä¾†æºäººè‡‰åœ–ç‰‡")
    parser.add_argument("--target", required=True, help="ç›®æ¨™å½±ç‰‡")
    parser.add_argument("--audio", required=True, help="è¦åˆä½µçš„éŸ³è¨Šæª”")
    parser.add_argument("--output", required=True, help="æœ€çµ‚è¼¸å‡ºå½±ç‰‡è·¯å¾‘")
    parser.add_argument("--gpu", action="store_true", help="ä½¿ç”¨ GPU åŠ é€Ÿ")
    parser.add_argument("--enhance", action="store_true", help="å•Ÿç”¨ GFPGAN å¢å¼·è‡‰éƒ¨ç´°ç¯€")
    args = parser.parse_args()

    temp_video = "temp_swap.mp4"  # æš«å­˜æ›è‡‰å½±ç‰‡

    # 1ï¸âƒ£ æ›è‡‰å½±ç‰‡
    swapper = FaceSwapper(use_gpu=args.gpu, enhance=args.enhance)
    if swapper.swap_video(args.source, args.target, temp_video):
        # 2ï¸âƒ£ åˆä½µéŸ³è¨Š
        merge_audio(temp_video, args.audio, args.output)
        # 3ï¸âƒ£ åˆªé™¤æš«å­˜å½±ç‰‡
        os.remove(temp_video)

if __name__ == "__main__":
    main()
